{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000/6473] Tokenized the captions.\n",
      "[2000/6473] Tokenized the captions.\n",
      "[3000/6473] Tokenized the captions.\n",
      "[4000/6473] Tokenized the captions.\n",
      "[5000/6473] Tokenized the captions.\n",
      "[6000/6473] Tokenized the captions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "import torch\n",
    "import argparse\n",
    "from models import EncoderCNN, SentenceLSTM, WordLSTM\n",
    "from collections import Counter\n",
    "\n",
    "class Vocabulary(object):\n",
    "    \"\"\"Simple vocabulary wrapper.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = {}\n",
    "        self.idx = 0\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if not word in self.word2idx:\n",
    "            self.word2idx[word] = self.idx\n",
    "            self.idx2word[self.idx] = word\n",
    "            self.idx += 1\n",
    "\n",
    "    def __call__(self, word):\n",
    "        if not word in self.word2idx:\n",
    "            return self.word2idx['<unk>']\n",
    "        return self.word2idx[word]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.word2idx)\n",
    "\n",
    "\n",
    "from dataloader import get_loader\n",
    "from score import evalscores\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from nltk.translate.bleu_score import corpus_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cococaption.pycocotools.coco import COCO\n",
    "from cococaption.pycocoevalcap.eval import COCOEvalCap\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class Vocabulary(object):\n",
    "    \"\"\"Simple vocabulary wrapper.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = {}\n",
    "        self.idx = 0\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if not word in self.word2idx:\n",
    "            self.word2idx[word] = self.idx\n",
    "            self.idx2word[self.idx] = word\n",
    "            self.idx += 1\n",
    "\n",
    "    def __call__(self, word):\n",
    "        if not word in self.word2idx:\n",
    "            return self.word2idx['<unk>']\n",
    "        return self.word2idx[word]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.word2idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue May  5 17:46:01 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.64.00    Driver Version: 440.64.00    CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-DGXS...  Off  | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   51C    P0   225W / 300W |  14494MiB / 16155MiB |     47%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-DGXS...  Off  | 00000000:08:00.0 Off |                    0 |\n",
      "| N/A   54C    P0   268W / 300W |  13748MiB / 16158MiB |     90%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-DGXS...  Off  | 00000000:0E:00.0 Off |                    0 |\n",
      "| N/A   47C    P0    56W / 300W |   3776MiB / 16158MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-DGXS...  Off  | 00000000:0F:00.0 Off |                    0 |\n",
      "| N/A   47C    P0    56W / 300W |   1426MiB / 16158MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     12913      C   /usr/local/bin/python3.6                   14483MiB |\n",
      "|    1      8981      C   python3                                    13737MiB |\n",
      "|    2      6551      C   /home/dchesakov/anaconda3/bin/python        3765MiB |\n",
      "|    3      5378      C   /opt/.pyenv/versions/3.7.4/bin/python       1415MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--save_step'], dest='save_step', nargs=None, const=None, default=1000, type=<class 'int'>, choices=None, help='step size for saving trained models', metavar=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--img_size', type = int, default = 224, help = 'size to which image is to be resized')\n",
    "parser.add_argument('--crop_size', type = int, default = 224, help = 'size to which the image is to be cropped')\n",
    "parser.add_argument('--device_number', type = str, default = \"0\", help = 'which GPU to run experiment on')\n",
    "\n",
    "\n",
    "parser.add_argument('--int_stop_dim', type = int, default = 64, help = 'intermediate state dimension of stop vector network')\n",
    "parser.add_argument('--sent_hidden_dim', type = int, default = 512, help = 'hidden state dimension of sentence LSTM')\n",
    "parser.add_argument('--sent_input_dim', type = int, default = 1024, help = 'dimension of input to sentence LSTM')\n",
    "parser.add_argument('--word_hidden_dim', type = int, default = 512, help = 'hidden state dimension of word LSTM')\n",
    "parser.add_argument('--word_input_dim', type = int, default = 512, help = 'dimension of input to word LSTM')\n",
    "parser.add_argument('--att_dim', type = int, default = 64, help = 'dimension of intermediate state in co-attention network')\n",
    "parser.add_argument('--num_layers', type = int, default = 1, help = 'number of layers in word LSTM')\n",
    "\n",
    "\n",
    "parser.add_argument('--lambda_sent', type = int, default = 1, help = 'weight for cross-entropy loss of stop vectors from sentence LSTM')    \n",
    "parser.add_argument('--lambda_word', type = int, default = 1, help = 'weight for cross-entropy loss of words predicted from word LSTM with target words')\n",
    "\n",
    "\n",
    "parser.add_argument('--batch_size', type = int, default = 8, help = 'size of the batch')\n",
    "parser.add_argument('--shuffle', type = bool, default = True, help = 'shuffle the instances in dataset')\n",
    "parser.add_argument('--num_workers', type = int, default = 0, help = 'number of workers for the dataloader')\n",
    "parser.add_argument('--num_epochs', type = int, default = 8, help = 'number of epochs to train the model')\n",
    "parser.add_argument('--learning_rate_cnn', type = int, default = 1e-5, help = 'learning rate for CNN Encoder')\n",
    "parser.add_argument('--learning_rate_lstm', type = int, default = 5e-3, help = 'learning rate for LSTM Decoder')\n",
    "\n",
    "\n",
    "parser.add_argument('--log_step', type=int , default=10, help='step size for prining log info')\n",
    "parser.add_argument('--save_step', type=int , default=1000, help='step size for saving trained models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]= args.device_number\n",
    "args.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(att_dim=64, batch_size=8, crop_size=224, device=device(type='cuda'), device_number='0', img_size=224, int_stop_dim=64, lambda_sent=1, lambda_word=1, learning_rate_cnn=1e-05, learning_rate_lstm=0.005, log_step=10, num_epochs=8, num_layers=1, num_workers=0, save_step=1000, sent_hidden_dim=512, sent_input_dim=1024, shuffle=True, word_hidden_dim=512, word_input_dim=512)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size:  743\n",
      "<start>\n",
      "[['the cardiomediastinal silhouette is normal in size and contour.', 'no focal consolidation pneumothorax or large pleural effusion.', 'negative for acute displaced rib fracture.', 'no discrete xxxx <unk> visualized.', 'contrast within the bilateral renal <unk> <unk>.', 'contrast also probably within the left colon.']]\n",
      "[]\n",
      "Bleu_1: 0.000\n",
      "Bleu_2: 0.000\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "ROUGE_L: 0.000\n",
      "CIDEr: 0.000\n",
      "Epoch [0/8], Step [0/810], Loss: 54.6027\n",
      "Epoch [0/8], Step [10/810], Loss: 7.1921\n",
      "Epoch [0/8], Step [20/810], Loss: 7.3709\n",
      "Epoch [0/8], Step [30/810], Loss: 7.4790\n",
      "Epoch [0/8], Step [40/810], Loss: 6.0623\n",
      "Epoch [0/8], Step [50/810], Loss: 4.7547\n",
      "Epoch [0/8], Step [60/810], Loss: 6.1365\n",
      "Epoch [0/8], Step [70/810], Loss: 3.6706\n",
      "Epoch [0/8], Step [80/810], Loss: 4.0334\n",
      "Epoch [0/8], Step [90/810], Loss: 5.2055\n",
      "Epoch [0/8], Step [100/810], Loss: 4.9751\n",
      "Epoch [0/8], Step [110/810], Loss: 5.6967\n",
      "Epoch [0/8], Step [120/810], Loss: 5.8410\n",
      "Epoch [0/8], Step [130/810], Loss: 4.6192\n",
      "Epoch [0/8], Step [140/810], Loss: 4.7063\n",
      "Epoch [0/8], Step [150/810], Loss: 4.3942\n",
      "Epoch [0/8], Step [160/810], Loss: 5.2244\n",
      "Epoch [0/8], Step [170/810], Loss: 3.8732\n",
      "Epoch [0/8], Step [180/810], Loss: 5.3732\n",
      "Epoch [0/8], Step [190/810], Loss: 4.1912\n",
      "Epoch [0/8], Step [200/810], Loss: 3.5061\n",
      "Epoch [0/8], Step [210/810], Loss: 3.2282\n",
      "Epoch [0/8], Step [220/810], Loss: 4.0202\n",
      "Epoch [0/8], Step [230/810], Loss: 4.4132\n",
      "Epoch [0/8], Step [240/810], Loss: 4.2853\n",
      "Epoch [0/8], Step [250/810], Loss: 5.2076\n",
      "Epoch [0/8], Step [260/810], Loss: 4.4138\n",
      "Epoch [0/8], Step [270/810], Loss: 3.7974\n",
      "Epoch [0/8], Step [280/810], Loss: 4.5025\n",
      "Epoch [0/8], Step [290/810], Loss: 4.0858\n",
      "Epoch [0/8], Step [300/810], Loss: 3.2218\n",
      "Epoch [0/8], Step [310/810], Loss: 4.9288\n",
      "Epoch [0/8], Step [320/810], Loss: 4.1451\n",
      "Epoch [0/8], Step [330/810], Loss: 4.8838\n",
      "Epoch [0/8], Step [340/810], Loss: 4.8425\n",
      "Epoch [0/8], Step [350/810], Loss: 2.7874\n",
      "Epoch [0/8], Step [360/810], Loss: 4.7583\n",
      "Epoch [0/8], Step [370/810], Loss: 3.0260\n",
      "Epoch [0/8], Step [380/810], Loss: 3.6943\n",
      "Epoch [0/8], Step [390/810], Loss: 3.5412\n",
      "Epoch [0/8], Step [400/810], Loss: 5.5352\n",
      "Epoch [0/8], Step [410/810], Loss: 4.2968\n",
      "Epoch [0/8], Step [420/810], Loss: 4.6974\n",
      "Epoch [0/8], Step [430/810], Loss: 3.2320\n",
      "Epoch [0/8], Step [440/810], Loss: 3.2712\n",
      "Epoch [0/8], Step [450/810], Loss: 4.6941\n",
      "Epoch [0/8], Step [460/810], Loss: 4.8455\n",
      "Epoch [0/8], Step [470/810], Loss: 6.5476\n",
      "Epoch [0/8], Step [480/810], Loss: 2.9467\n",
      "Epoch [0/8], Step [490/810], Loss: 4.6392\n",
      "Epoch [0/8], Step [500/810], Loss: 4.8347\n",
      "Epoch [0/8], Step [510/810], Loss: 4.0745\n",
      "Epoch [0/8], Step [520/810], Loss: 3.8350\n",
      "Epoch [0/8], Step [530/810], Loss: 3.7248\n",
      "Epoch [0/8], Step [540/810], Loss: 4.5521\n",
      "Epoch [0/8], Step [550/810], Loss: 4.1814\n",
      "Epoch [0/8], Step [560/810], Loss: 3.5242\n",
      "Epoch [0/8], Step [570/810], Loss: 4.8595\n",
      "Epoch [0/8], Step [580/810], Loss: 2.6841\n",
      "Epoch [0/8], Step [590/810], Loss: 3.8834\n",
      "Epoch [0/8], Step [600/810], Loss: 6.5105\n",
      "Epoch [0/8], Step [610/810], Loss: 6.0771\n",
      "Epoch [0/8], Step [620/810], Loss: 2.7786\n",
      "Epoch [0/8], Step [630/810], Loss: 3.5555\n",
      "Epoch [0/8], Step [640/810], Loss: 3.5517\n",
      "Epoch [0/8], Step [650/810], Loss: 3.3566\n",
      "Epoch [0/8], Step [660/810], Loss: 4.0845\n",
      "Epoch [0/8], Step [670/810], Loss: 3.0248\n",
      "Epoch [0/8], Step [680/810], Loss: 4.1777\n",
      "Epoch [0/8], Step [690/810], Loss: 4.0039\n",
      "Epoch [0/8], Step [700/810], Loss: 3.9044\n",
      "Epoch [0/8], Step [710/810], Loss: 4.6919\n",
      "Epoch [0/8], Step [720/810], Loss: 3.5286\n",
      "Epoch [0/8], Step [730/810], Loss: 5.0838\n",
      "Epoch [0/8], Step [740/810], Loss: 4.1338\n",
      "Epoch [0/8], Step [750/810], Loss: 4.5988\n",
      "Epoch [0/8], Step [760/810], Loss: 2.6363\n",
      "Epoch [0/8], Step [770/810], Loss: 3.1922\n",
      "Epoch [0/8], Step [780/810], Loss: 4.2256\n",
      "Epoch [0/8], Step [790/810], Loss: 3.9664\n",
      "Epoch [0/8], Step [800/810], Loss: 2.5573\n",
      "[['there is stable cardiomegaly.', 'aorta is calcified and tortuous.', 'there are multiple pleural calcifications xxxx representing prior <unk> <unk>.', 'these appear unchanged.', 'there is no pneumothorax pleural effusion or xxxx focal airspace consolidation.']]\n",
      "['the is no mild.']\n",
      "Bleu_1: 0.026\n",
      "Bleu_2: 0.020\n",
      "Bleu_3: 0.017\n",
      "Bleu_4: 0.014\n",
      "ROUGE_L: 0.240\n",
      "CIDEr: 0.149\n",
      "Epoch [1/8], Step [0/810], Loss: 3.2384\n",
      "Epoch [1/8], Step [10/810], Loss: 2.9309\n",
      "Epoch [1/8], Step [20/810], Loss: 6.1149\n",
      "Epoch [1/8], Step [30/810], Loss: 3.5376\n",
      "Epoch [1/8], Step [40/810], Loss: 3.8380\n",
      "Epoch [1/8], Step [50/810], Loss: 5.4053\n",
      "Epoch [1/8], Step [60/810], Loss: 5.0385\n",
      "Epoch [1/8], Step [70/810], Loss: 2.6844\n",
      "Epoch [1/8], Step [80/810], Loss: 4.5701\n",
      "Epoch [1/8], Step [90/810], Loss: 3.9179\n",
      "Epoch [1/8], Step [100/810], Loss: 3.3834\n",
      "Epoch [1/8], Step [110/810], Loss: 2.5045\n",
      "Epoch [1/8], Step [120/810], Loss: 4.0073\n",
      "Epoch [1/8], Step [130/810], Loss: 3.6109\n",
      "Epoch [1/8], Step [140/810], Loss: 3.3447\n",
      "Epoch [1/8], Step [150/810], Loss: 3.9626\n",
      "Epoch [1/8], Step [160/810], Loss: 3.4761\n",
      "Epoch [1/8], Step [170/810], Loss: 3.1957\n",
      "Epoch [1/8], Step [180/810], Loss: 3.0667\n",
      "Epoch [1/8], Step [190/810], Loss: 4.6340\n",
      "Epoch [1/8], Step [200/810], Loss: 4.3864\n",
      "Epoch [1/8], Step [210/810], Loss: 3.8543\n",
      "Epoch [1/8], Step [220/810], Loss: 2.3364\n",
      "Epoch [1/8], Step [230/810], Loss: 3.6410\n",
      "Epoch [1/8], Step [240/810], Loss: 5.4845\n",
      "Epoch [1/8], Step [250/810], Loss: 3.6446\n",
      "Epoch [1/8], Step [260/810], Loss: 4.6596\n",
      "Epoch [1/8], Step [270/810], Loss: 4.0888\n",
      "Epoch [1/8], Step [280/810], Loss: 5.0257\n",
      "Epoch [1/8], Step [290/810], Loss: 2.7117\n",
      "Epoch [1/8], Step [300/810], Loss: 5.2616\n",
      "Epoch [1/8], Step [310/810], Loss: 3.2510\n",
      "Epoch [1/8], Step [320/810], Loss: 5.5912\n",
      "Epoch [1/8], Step [330/810], Loss: 3.3898\n",
      "Epoch [1/8], Step [340/810], Loss: 3.2084\n",
      "Epoch [1/8], Step [350/810], Loss: 3.5623\n",
      "Epoch [1/8], Step [360/810], Loss: 3.4423\n",
      "Epoch [1/8], Step [370/810], Loss: 3.0743\n",
      "Epoch [1/8], Step [380/810], Loss: 3.3738\n",
      "Epoch [1/8], Step [390/810], Loss: 2.5629\n",
      "Epoch [1/8], Step [400/810], Loss: 3.9245\n",
      "Epoch [1/8], Step [410/810], Loss: 3.6821\n",
      "Epoch [1/8], Step [420/810], Loss: 5.1022\n",
      "Epoch [1/8], Step [430/810], Loss: 3.6434\n",
      "Epoch [1/8], Step [440/810], Loss: 4.0464\n",
      "Epoch [1/8], Step [450/810], Loss: 3.7992\n",
      "Epoch [1/8], Step [460/810], Loss: 3.4631\n",
      "Epoch [1/8], Step [470/810], Loss: 5.5024\n",
      "Epoch [1/8], Step [480/810], Loss: 3.4095\n",
      "Epoch [1/8], Step [490/810], Loss: 4.9950\n",
      "Epoch [1/8], Step [500/810], Loss: 5.6720\n",
      "Epoch [1/8], Step [510/810], Loss: 4.7885\n",
      "Epoch [1/8], Step [520/810], Loss: 3.6466\n",
      "Epoch [1/8], Step [530/810], Loss: 3.6872\n",
      "Epoch [1/8], Step [540/810], Loss: 4.4726\n",
      "Epoch [1/8], Step [550/810], Loss: 3.2981\n",
      "Epoch [1/8], Step [560/810], Loss: 3.5090\n",
      "Epoch [1/8], Step [570/810], Loss: 4.1589\n",
      "Epoch [1/8], Step [580/810], Loss: 2.7824\n",
      "Epoch [1/8], Step [590/810], Loss: 4.3855\n",
      "Epoch [1/8], Step [600/810], Loss: 3.0947\n",
      "Epoch [1/8], Step [610/810], Loss: 3.2103\n",
      "Epoch [1/8], Step [620/810], Loss: 3.1244\n",
      "Epoch [1/8], Step [630/810], Loss: 4.0855\n",
      "Epoch [1/8], Step [640/810], Loss: 4.5878\n",
      "Epoch [1/8], Step [650/810], Loss: 4.0646\n",
      "Epoch [1/8], Step [660/810], Loss: 2.5478\n",
      "Epoch [1/8], Step [670/810], Loss: 4.0046\n",
      "Epoch [1/8], Step [680/810], Loss: 2.9400\n",
      "Epoch [1/8], Step [690/810], Loss: 5.7293\n",
      "Epoch [1/8], Step [700/810], Loss: 4.1415\n",
      "Epoch [1/8], Step [710/810], Loss: 6.0602\n",
      "Epoch [1/8], Step [720/810], Loss: 4.1319\n",
      "Epoch [1/8], Step [730/810], Loss: 3.8398\n",
      "Epoch [1/8], Step [740/810], Loss: 3.0618\n",
      "Epoch [1/8], Step [750/810], Loss: 3.4583\n",
      "Epoch [1/8], Step [760/810], Loss: 3.4665\n",
      "Epoch [1/8], Step [770/810], Loss: 2.4682\n",
      "Epoch [1/8], Step [780/810], Loss: 3.8023\n",
      "Epoch [1/8], Step [790/810], Loss: 3.4158\n",
      "Epoch [1/8], Step [800/810], Loss: 2.9743\n",
      "[['the cardiomediastinal silhouette is normal in size and contour.', 'no focal consolidation pneumothorax or large pleural effusion.', 'normal xxxx.', 'xxxx cholecystectomy.']]\n",
      "['the lungs silhouette is within in size and contour.']\n",
      "Bleu_1: 0.027\n",
      "Bleu_2: 0.022\n",
      "Bleu_3: 0.018\n",
      "Bleu_4: 0.016\n",
      "ROUGE_L: 0.244\n",
      "CIDEr: 0.155\n",
      "Epoch [2/8], Step [0/810], Loss: 3.2087\n",
      "Epoch [2/8], Step [10/810], Loss: 2.5797\n",
      "Epoch [2/8], Step [20/810], Loss: 2.5361\n",
      "Epoch [2/8], Step [30/810], Loss: 3.2688\n",
      "Epoch [2/8], Step [40/810], Loss: 4.3018\n",
      "Epoch [2/8], Step [50/810], Loss: 3.3964\n",
      "Epoch [2/8], Step [60/810], Loss: 2.6629\n",
      "Epoch [2/8], Step [70/810], Loss: 3.2504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/8], Step [80/810], Loss: 3.5116\n",
      "Epoch [2/8], Step [90/810], Loss: 3.1679\n",
      "Epoch [2/8], Step [100/810], Loss: 2.7711\n",
      "Epoch [2/8], Step [110/810], Loss: 3.3052\n",
      "Epoch [2/8], Step [120/810], Loss: 3.7961\n",
      "Epoch [2/8], Step [130/810], Loss: 3.2859\n",
      "Epoch [2/8], Step [140/810], Loss: 4.7169\n",
      "Epoch [2/8], Step [150/810], Loss: 2.7369\n",
      "Epoch [2/8], Step [160/810], Loss: 3.8772\n",
      "Epoch [2/8], Step [170/810], Loss: 2.9956\n",
      "Epoch [2/8], Step [180/810], Loss: 4.7573\n",
      "Epoch [2/8], Step [190/810], Loss: 2.3957\n",
      "Epoch [2/8], Step [200/810], Loss: 2.2857\n",
      "Epoch [2/8], Step [210/810], Loss: 4.4098\n",
      "Epoch [2/8], Step [220/810], Loss: 4.7864\n",
      "Epoch [2/8], Step [230/810], Loss: 3.5988\n",
      "Epoch [2/8], Step [240/810], Loss: 2.0672\n",
      "Epoch [2/8], Step [250/810], Loss: 3.0875\n",
      "Epoch [2/8], Step [260/810], Loss: 4.4701\n",
      "Epoch [2/8], Step [270/810], Loss: 4.8708\n",
      "Epoch [2/8], Step [280/810], Loss: 3.3186\n",
      "Epoch [2/8], Step [290/810], Loss: 2.5407\n",
      "Epoch [2/8], Step [300/810], Loss: 2.9657\n",
      "Epoch [2/8], Step [310/810], Loss: 3.1279\n",
      "Epoch [2/8], Step [320/810], Loss: 3.5975\n",
      "Epoch [2/8], Step [330/810], Loss: 2.9943\n",
      "Epoch [2/8], Step [340/810], Loss: 2.8650\n",
      "Epoch [2/8], Step [350/810], Loss: 3.9171\n",
      "Epoch [2/8], Step [360/810], Loss: 3.7025\n",
      "Epoch [2/8], Step [370/810], Loss: 3.5145\n",
      "Epoch [2/8], Step [380/810], Loss: 3.0191\n",
      "Epoch [2/8], Step [390/810], Loss: 3.4329\n",
      "Epoch [2/8], Step [400/810], Loss: 2.5621\n",
      "Epoch [2/8], Step [410/810], Loss: 4.0549\n",
      "Epoch [2/8], Step [420/810], Loss: 2.8159\n",
      "Epoch [2/8], Step [430/810], Loss: 3.0574\n",
      "Epoch [2/8], Step [440/810], Loss: 2.5711\n",
      "Epoch [2/8], Step [450/810], Loss: 3.7380\n",
      "Epoch [2/8], Step [460/810], Loss: 3.5273\n",
      "Epoch [2/8], Step [470/810], Loss: 2.9633\n",
      "Epoch [2/8], Step [480/810], Loss: 4.0670\n",
      "Epoch [2/8], Step [490/810], Loss: 2.3771\n",
      "Epoch [2/8], Step [500/810], Loss: 3.9910\n",
      "Epoch [2/8], Step [510/810], Loss: 3.0600\n",
      "Epoch [2/8], Step [520/810], Loss: 3.3058\n",
      "Epoch [2/8], Step [530/810], Loss: 4.1866\n",
      "Epoch [2/8], Step [540/810], Loss: 2.9176\n",
      "Epoch [2/8], Step [550/810], Loss: 2.6947\n",
      "Epoch [2/8], Step [560/810], Loss: 3.8504\n",
      "Epoch [2/8], Step [570/810], Loss: 4.6108\n",
      "Epoch [2/8], Step [580/810], Loss: 3.1568\n",
      "Epoch [2/8], Step [590/810], Loss: 2.6471\n",
      "Epoch [2/8], Step [600/810], Loss: 3.0079\n",
      "Epoch [2/8], Step [610/810], Loss: 4.2514\n",
      "Epoch [2/8], Step [620/810], Loss: 3.7332\n",
      "Epoch [2/8], Step [630/810], Loss: 3.8310\n",
      "Epoch [2/8], Step [640/810], Loss: 2.6114\n",
      "Epoch [2/8], Step [650/810], Loss: 2.8132\n",
      "Epoch [2/8], Step [660/810], Loss: 3.3969\n",
      "Epoch [2/8], Step [670/810], Loss: 2.3121\n",
      "Epoch [2/8], Step [680/810], Loss: 3.8598\n",
      "Epoch [2/8], Step [690/810], Loss: 2.7402\n",
      "Epoch [2/8], Step [700/810], Loss: 3.0207\n",
      "Epoch [2/8], Step [710/810], Loss: 3.4863\n",
      "Epoch [2/8], Step [720/810], Loss: 3.0350\n",
      "Epoch [2/8], Step [730/810], Loss: 3.9213\n",
      "Epoch [2/8], Step [740/810], Loss: 2.8307\n",
      "Epoch [2/8], Step [750/810], Loss: 3.6188\n",
      "Epoch [2/8], Step [760/810], Loss: 3.2515\n",
      "Epoch [2/8], Step [770/810], Loss: 3.0393\n",
      "Epoch [2/8], Step [780/810], Loss: 5.0326\n",
      "Epoch [2/8], Step [790/810], Loss: 3.1510\n",
      "Epoch [2/8], Step [800/810], Loss: 3.6013\n",
      "[['there is prominence of the right heart xxxx consistent with right atrial enlargement.', 'a xxxx density is demonstrated on the frontal view with exaggerated posterior projection of the cardiac silhouette suggesting left atrial enlargement.', 'the cardiac silhouette is overall enlarged.', 'the mediastinal contours are otherwise within normal limits for appearance.', 'no focal areas of pulmonary consolidation.', 'no pneumothorax.', 'no pleural effusion.', 'mild pulmonary hyperexpansion.', 'mild left apical pleural thickening.', 'moderate degenerative changes of the thoracic spine.']]\n",
      "['the is no of the mediastinum paratracheal xxxx with known atrial enlargement.']\n",
      "Bleu_1: 0.270\n",
      "Bleu_2: 0.208\n",
      "Bleu_3: 0.165\n",
      "Bleu_4: 0.135\n",
      "ROUGE_L: 0.376\n",
      "CIDEr: 0.972\n",
      "Epoch [3/8], Step [0/810], Loss: 3.5332\n",
      "Epoch [3/8], Step [10/810], Loss: 2.2362\n",
      "Epoch [3/8], Step [20/810], Loss: 2.4279\n",
      "Epoch [3/8], Step [30/810], Loss: 2.5053\n",
      "Epoch [3/8], Step [40/810], Loss: 2.9801\n",
      "Epoch [3/8], Step [50/810], Loss: 2.5851\n",
      "Epoch [3/8], Step [60/810], Loss: 2.7082\n",
      "Epoch [3/8], Step [70/810], Loss: 4.0886\n",
      "Epoch [3/8], Step [80/810], Loss: 3.1227\n",
      "Epoch [3/8], Step [90/810], Loss: 3.5903\n",
      "Epoch [3/8], Step [100/810], Loss: 2.6442\n",
      "Epoch [3/8], Step [110/810], Loss: 4.1501\n",
      "Epoch [3/8], Step [120/810], Loss: 2.7620\n",
      "Epoch [3/8], Step [130/810], Loss: 3.4486\n",
      "Epoch [3/8], Step [140/810], Loss: 3.2664\n",
      "Epoch [3/8], Step [150/810], Loss: 2.8895\n",
      "Epoch [3/8], Step [160/810], Loss: 2.7913\n",
      "Epoch [3/8], Step [170/810], Loss: 3.2957\n",
      "Epoch [3/8], Step [180/810], Loss: 6.1703\n",
      "Epoch [3/8], Step [190/810], Loss: 2.9601\n",
      "Epoch [3/8], Step [200/810], Loss: 3.7138\n",
      "Epoch [3/8], Step [210/810], Loss: 2.3529\n",
      "Epoch [3/8], Step [220/810], Loss: 2.4093\n",
      "Epoch [3/8], Step [230/810], Loss: 4.1794\n",
      "Epoch [3/8], Step [240/810], Loss: 3.2220\n",
      "Epoch [3/8], Step [250/810], Loss: 3.4553\n",
      "Epoch [3/8], Step [260/810], Loss: 3.8357\n",
      "Epoch [3/8], Step [270/810], Loss: 3.2348\n",
      "Epoch [3/8], Step [280/810], Loss: 3.4463\n",
      "Epoch [3/8], Step [290/810], Loss: 3.5016\n",
      "Epoch [3/8], Step [300/810], Loss: 4.0970\n",
      "Epoch [3/8], Step [310/810], Loss: 3.7581\n",
      "Epoch [3/8], Step [320/810], Loss: 3.3484\n",
      "Epoch [3/8], Step [330/810], Loss: 2.7074\n",
      "Epoch [3/8], Step [340/810], Loss: 3.4213\n",
      "Epoch [3/8], Step [350/810], Loss: 2.6527\n",
      "Epoch [3/8], Step [360/810], Loss: 3.3440\n",
      "Epoch [3/8], Step [370/810], Loss: 2.9389\n",
      "Epoch [3/8], Step [380/810], Loss: 4.1391\n",
      "Epoch [3/8], Step [390/810], Loss: 4.2346\n",
      "Epoch [3/8], Step [400/810], Loss: 3.0577\n",
      "Epoch [3/8], Step [410/810], Loss: 2.5434\n",
      "Epoch [3/8], Step [420/810], Loss: 3.6331\n",
      "Epoch [3/8], Step [430/810], Loss: 3.0018\n",
      "Epoch [3/8], Step [440/810], Loss: 3.7363\n",
      "Epoch [3/8], Step [450/810], Loss: 2.8914\n",
      "Epoch [3/8], Step [460/810], Loss: 2.2536\n",
      "Epoch [3/8], Step [470/810], Loss: 3.2939\n",
      "Epoch [3/8], Step [480/810], Loss: 4.8303\n",
      "Epoch [3/8], Step [490/810], Loss: 3.0374\n",
      "Epoch [3/8], Step [500/810], Loss: 3.4660\n",
      "Epoch [3/8], Step [510/810], Loss: 2.5481\n",
      "Epoch [3/8], Step [520/810], Loss: 3.8882\n",
      "Epoch [3/8], Step [530/810], Loss: 2.9543\n",
      "Epoch [3/8], Step [540/810], Loss: 3.0865\n",
      "Epoch [3/8], Step [550/810], Loss: 3.5331\n",
      "Epoch [3/8], Step [560/810], Loss: 3.2312\n",
      "Epoch [3/8], Step [570/810], Loss: 4.0021\n",
      "Epoch [3/8], Step [580/810], Loss: 3.5052\n",
      "Epoch [3/8], Step [590/810], Loss: 2.5976\n",
      "Epoch [3/8], Step [600/810], Loss: 2.8117\n",
      "Epoch [3/8], Step [610/810], Loss: 2.2903\n",
      "Epoch [3/8], Step [620/810], Loss: 3.7999\n",
      "Epoch [3/8], Step [630/810], Loss: 2.8921\n",
      "Epoch [3/8], Step [640/810], Loss: 4.6760\n",
      "Epoch [3/8], Step [650/810], Loss: 3.0801\n",
      "Epoch [3/8], Step [660/810], Loss: 4.8786\n",
      "Epoch [3/8], Step [670/810], Loss: 4.3866\n",
      "Epoch [3/8], Step [680/810], Loss: 3.4204\n",
      "Epoch [3/8], Step [690/810], Loss: 2.8172\n",
      "Epoch [3/8], Step [700/810], Loss: 2.7824\n",
      "Epoch [3/8], Step [710/810], Loss: 3.2816\n",
      "Epoch [3/8], Step [720/810], Loss: 3.2107\n",
      "Epoch [3/8], Step [730/810], Loss: 2.4865\n",
      "Epoch [3/8], Step [740/810], Loss: 3.4196\n",
      "Epoch [3/8], Step [750/810], Loss: 4.3017\n",
      "Epoch [3/8], Step [760/810], Loss: 3.7935\n",
      "Epoch [3/8], Step [770/810], Loss: 3.3132\n",
      "Epoch [3/8], Step [780/810], Loss: 3.6617\n",
      "Epoch [3/8], Step [790/810], Loss: 3.7966\n",
      "Epoch [3/8], Step [800/810], Loss: 2.9008\n",
      "[['unchanged cardiomegaly.', 'negative for pneumothorax or focal consolidation.', 'no large effusion.', 'mildly prominent interstitial opacities.']]\n",
      "['the degenerative.', 'the for acute pleural pleural airspace.', 'the pleural pleural or.', 'the low perihilar markings.', '.', '.', '.']\n",
      "Bleu_1: 0.506\n",
      "Bleu_2: 0.397\n",
      "Bleu_3: 0.314\n",
      "Bleu_4: 0.253\n",
      "ROUGE_L: 0.521\n",
      "CIDEr: 1.873\n",
      "Epoch [4/8], Step [0/810], Loss: 2.5655\n",
      "Epoch [4/8], Step [10/810], Loss: 2.7657\n",
      "Epoch [4/8], Step [20/810], Loss: 3.5628\n",
      "Epoch [4/8], Step [30/810], Loss: 3.2436\n",
      "Epoch [4/8], Step [40/810], Loss: 3.5154\n",
      "Epoch [4/8], Step [50/810], Loss: 4.1701\n",
      "Epoch [4/8], Step [60/810], Loss: 3.9882\n",
      "Epoch [4/8], Step [70/810], Loss: 4.1678\n",
      "Epoch [4/8], Step [80/810], Loss: 2.6224\n",
      "Epoch [4/8], Step [90/810], Loss: 3.6321\n",
      "Epoch [4/8], Step [100/810], Loss: 3.7473\n",
      "Epoch [4/8], Step [110/810], Loss: 3.1929\n",
      "Epoch [4/8], Step [120/810], Loss: 3.4918\n",
      "Epoch [4/8], Step [130/810], Loss: 2.8913\n",
      "Epoch [4/8], Step [140/810], Loss: 3.0334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/8], Step [150/810], Loss: 2.9120\n",
      "Epoch [4/8], Step [160/810], Loss: 3.4075\n",
      "Epoch [4/8], Step [170/810], Loss: 4.3114\n",
      "Epoch [4/8], Step [180/810], Loss: 3.1094\n",
      "Epoch [4/8], Step [190/810], Loss: 3.6887\n",
      "Epoch [4/8], Step [200/810], Loss: 3.5351\n",
      "Epoch [4/8], Step [210/810], Loss: 3.2751\n",
      "Epoch [4/8], Step [220/810], Loss: 4.9880\n",
      "Epoch [4/8], Step [230/810], Loss: 2.5801\n",
      "Epoch [4/8], Step [240/810], Loss: 3.8611\n",
      "Epoch [4/8], Step [250/810], Loss: 4.9627\n",
      "Epoch [4/8], Step [260/810], Loss: 2.3901\n",
      "Epoch [4/8], Step [270/810], Loss: 2.5259\n",
      "Epoch [4/8], Step [280/810], Loss: 3.5273\n",
      "Epoch [4/8], Step [290/810], Loss: 2.9043\n",
      "Epoch [4/8], Step [300/810], Loss: 3.6338\n",
      "Epoch [4/8], Step [310/810], Loss: 2.9178\n",
      "Epoch [4/8], Step [320/810], Loss: 3.0541\n",
      "Epoch [4/8], Step [330/810], Loss: 2.6960\n",
      "Epoch [4/8], Step [340/810], Loss: 4.1922\n",
      "Epoch [4/8], Step [350/810], Loss: 3.3126\n",
      "Epoch [4/8], Step [360/810], Loss: 3.5890\n",
      "Epoch [4/8], Step [370/810], Loss: 3.5961\n",
      "Epoch [4/8], Step [380/810], Loss: 2.2473\n",
      "Epoch [4/8], Step [390/810], Loss: 3.2957\n",
      "Epoch [4/8], Step [400/810], Loss: 3.3405\n",
      "Epoch [4/8], Step [410/810], Loss: 2.9324\n",
      "Epoch [4/8], Step [420/810], Loss: 1.8840\n",
      "Epoch [4/8], Step [430/810], Loss: 5.1015\n",
      "Epoch [4/8], Step [440/810], Loss: 4.0830\n",
      "Epoch [4/8], Step [450/810], Loss: 3.2239\n",
      "Epoch [4/8], Step [460/810], Loss: 3.7362\n",
      "Epoch [4/8], Step [470/810], Loss: 3.4881\n",
      "Epoch [4/8], Step [480/810], Loss: 2.4994\n",
      "Epoch [4/8], Step [490/810], Loss: 4.3490\n",
      "Epoch [4/8], Step [500/810], Loss: 2.6710\n",
      "Epoch [4/8], Step [510/810], Loss: 4.3422\n",
      "Epoch [4/8], Step [520/810], Loss: 3.2037\n",
      "Epoch [4/8], Step [530/810], Loss: 3.2506\n",
      "Epoch [4/8], Step [540/810], Loss: 3.2083\n",
      "Epoch [4/8], Step [550/810], Loss: 2.6699\n",
      "Epoch [4/8], Step [560/810], Loss: 4.1756\n",
      "Epoch [4/8], Step [570/810], Loss: 5.3348\n",
      "Epoch [4/8], Step [580/810], Loss: 3.7739\n",
      "Epoch [4/8], Step [590/810], Loss: 3.4751\n",
      "Epoch [4/8], Step [600/810], Loss: 2.6981\n",
      "Epoch [4/8], Step [610/810], Loss: 3.2448\n",
      "Epoch [4/8], Step [620/810], Loss: 3.9044\n",
      "Epoch [4/8], Step [630/810], Loss: 3.0799\n",
      "Epoch [4/8], Step [640/810], Loss: 3.4636\n",
      "Epoch [4/8], Step [650/810], Loss: 2.4270\n",
      "Epoch [4/8], Step [660/810], Loss: 3.2494\n",
      "Epoch [4/8], Step [670/810], Loss: 3.1651\n",
      "Epoch [4/8], Step [680/810], Loss: 4.0943\n",
      "Epoch [4/8], Step [690/810], Loss: 3.0335\n",
      "Epoch [4/8], Step [700/810], Loss: 4.3757\n",
      "Epoch [4/8], Step [710/810], Loss: 3.2028\n",
      "Epoch [4/8], Step [720/810], Loss: 2.6479\n",
      "Epoch [4/8], Step [730/810], Loss: 2.4528\n",
      "Epoch [4/8], Step [740/810], Loss: 3.0891\n",
      "Epoch [4/8], Step [750/810], Loss: 2.8313\n",
      "Epoch [4/8], Step [760/810], Loss: 3.1429\n",
      "Epoch [4/8], Step [770/810], Loss: 2.9347\n",
      "Epoch [4/8], Step [780/810], Loss: 3.2053\n",
      "Epoch [4/8], Step [790/810], Loss: 3.1133\n",
      "Epoch [4/8], Step [800/810], Loss: 2.5700\n",
      "[['heart size and mediastinal contours appear within normal limits.', 'hyperinflated lungs with flattening of diaphragms compatible with emphysema.', 'no focal consolidation pleural effusion or pneumothorax.', 'no acute bony abnormality.']]\n",
      "['the size and pulmonary contour appear within normal limits.', 'the lungs mildly of diaphragms compatible with emphysema.', 'the pleural airspace pneumothorax effusion or pneumothorax identified.', 'the pleural bony abnormality.', '.', '.', '.', '.', '.']\n",
      "Bleu_1: 0.535\n",
      "Bleu_2: 0.428\n",
      "Bleu_3: 0.348\n",
      "Bleu_4: 0.286\n",
      "ROUGE_L: 0.542\n",
      "CIDEr: 2.029\n",
      "Epoch [5/8], Step [0/810], Loss: 4.1896\n",
      "Epoch [5/8], Step [10/810], Loss: 2.9388\n",
      "Epoch [5/8], Step [20/810], Loss: 2.6910\n",
      "Epoch [5/8], Step [30/810], Loss: 3.0730\n",
      "Epoch [5/8], Step [40/810], Loss: 2.4654\n",
      "Epoch [5/8], Step [50/810], Loss: 2.3346\n",
      "Epoch [5/8], Step [60/810], Loss: 2.8786\n",
      "Epoch [5/8], Step [70/810], Loss: 3.8562\n",
      "Epoch [5/8], Step [80/810], Loss: 2.8978\n",
      "Epoch [5/8], Step [90/810], Loss: 2.0534\n",
      "Epoch [5/8], Step [100/810], Loss: 2.3772\n",
      "Epoch [5/8], Step [110/810], Loss: 3.9073\n",
      "Epoch [5/8], Step [120/810], Loss: 2.9065\n",
      "Epoch [5/8], Step [130/810], Loss: 3.4884\n",
      "Epoch [5/8], Step [140/810], Loss: 3.9243\n",
      "Epoch [5/8], Step [150/810], Loss: 2.9786\n",
      "Epoch [5/8], Step [160/810], Loss: 4.9433\n",
      "Epoch [5/8], Step [170/810], Loss: 2.9124\n",
      "Epoch [5/8], Step [180/810], Loss: 3.9051\n",
      "Epoch [5/8], Step [190/810], Loss: 1.9280\n",
      "Epoch [5/8], Step [200/810], Loss: 2.8253\n",
      "Epoch [5/8], Step [210/810], Loss: 4.3878\n",
      "Epoch [5/8], Step [220/810], Loss: 2.8699\n",
      "Epoch [5/8], Step [230/810], Loss: 3.3649\n",
      "Epoch [5/8], Step [240/810], Loss: 3.3091\n",
      "Epoch [5/8], Step [250/810], Loss: 4.1176\n",
      "Epoch [5/8], Step [260/810], Loss: 3.3187\n",
      "Epoch [5/8], Step [270/810], Loss: 5.0166\n",
      "Epoch [5/8], Step [280/810], Loss: 3.1593\n",
      "Epoch [5/8], Step [290/810], Loss: 1.8917\n",
      "Epoch [5/8], Step [300/810], Loss: 3.2468\n",
      "Epoch [5/8], Step [310/810], Loss: 3.5333\n",
      "Epoch [5/8], Step [320/810], Loss: 3.7010\n",
      "Epoch [5/8], Step [330/810], Loss: 4.0533\n",
      "Epoch [5/8], Step [340/810], Loss: 4.0321\n",
      "Epoch [5/8], Step [350/810], Loss: 2.5756\n",
      "Epoch [5/8], Step [360/810], Loss: 2.9717\n",
      "Epoch [5/8], Step [370/810], Loss: 3.3608\n",
      "Epoch [5/8], Step [380/810], Loss: 2.8121\n",
      "Epoch [5/8], Step [390/810], Loss: 3.5444\n",
      "Epoch [5/8], Step [400/810], Loss: 2.8298\n",
      "Epoch [5/8], Step [410/810], Loss: 3.3774\n",
      "Epoch [5/8], Step [420/810], Loss: 3.3506\n",
      "Epoch [5/8], Step [430/810], Loss: 1.9691\n",
      "Epoch [5/8], Step [440/810], Loss: 2.7195\n",
      "Epoch [5/8], Step [450/810], Loss: 2.8337\n",
      "Epoch [5/8], Step [460/810], Loss: 3.2291\n",
      "Epoch [5/8], Step [470/810], Loss: 3.8890\n",
      "Epoch [5/8], Step [480/810], Loss: 2.6075\n",
      "Epoch [5/8], Step [490/810], Loss: 2.9424\n",
      "Epoch [5/8], Step [500/810], Loss: 3.5779\n",
      "Epoch [5/8], Step [510/810], Loss: 3.3243\n",
      "Epoch [5/8], Step [520/810], Loss: 3.2012\n",
      "Epoch [5/8], Step [530/810], Loss: 3.6365\n",
      "Epoch [5/8], Step [540/810], Loss: 3.7141\n",
      "Epoch [5/8], Step [550/810], Loss: 3.8604\n",
      "Epoch [5/8], Step [560/810], Loss: 2.8459\n",
      "Epoch [5/8], Step [570/810], Loss: 2.3916\n",
      "Epoch [5/8], Step [580/810], Loss: 3.6122\n",
      "Epoch [5/8], Step [590/810], Loss: 2.5375\n",
      "Epoch [5/8], Step [600/810], Loss: 3.0186\n",
      "Epoch [5/8], Step [610/810], Loss: 4.0214\n",
      "Epoch [5/8], Step [620/810], Loss: 2.8768\n",
      "Epoch [5/8], Step [630/810], Loss: 3.2710\n",
      "Epoch [5/8], Step [640/810], Loss: 2.1734\n",
      "Epoch [5/8], Step [650/810], Loss: 3.2756\n",
      "Epoch [5/8], Step [660/810], Loss: 2.7505\n",
      "Epoch [5/8], Step [670/810], Loss: 3.9462\n",
      "Epoch [5/8], Step [680/810], Loss: 3.0443\n",
      "Epoch [5/8], Step [690/810], Loss: 4.1109\n",
      "Epoch [5/8], Step [700/810], Loss: 2.8441\n",
      "Epoch [5/8], Step [710/810], Loss: 3.4634\n",
      "Epoch [5/8], Step [720/810], Loss: 4.4029\n",
      "Epoch [5/8], Step [730/810], Loss: 3.6544\n",
      "Epoch [5/8], Step [740/810], Loss: 2.1086\n",
      "Epoch [5/8], Step [750/810], Loss: 2.9049\n",
      "Epoch [5/8], Step [760/810], Loss: 2.5320\n",
      "Epoch [5/8], Step [770/810], Loss: 2.1296\n",
      "Epoch [5/8], Step [780/810], Loss: 5.6646\n",
      "Epoch [5/8], Step [790/810], Loss: 2.4830\n",
      "Epoch [5/8], Step [800/810], Loss: 2.9808\n",
      "[['the lungs are clear.', 'heart size is normal.', 'no pneumothorax.', 'there is a cardiac xxxx with leads terminating in the right atrium and right ventricle.', 'there are atherosclerotic calcifications.']]\n",
      "['the lungs are clear.', 'the size and normal.', 'the focal or.', 'the is no calcified xxxx with leads terminating in the right atrium and one ventricle.', 'the is no changes of.']\n",
      "Bleu_1: 0.600\n",
      "Bleu_2: 0.478\n",
      "Bleu_3: 0.386\n",
      "Bleu_4: 0.317\n",
      "ROUGE_L: 0.586\n",
      "CIDEr: 2.397\n",
      "Epoch [6/8], Step [0/810], Loss: 3.0612\n",
      "Epoch [6/8], Step [10/810], Loss: 3.6103\n",
      "Epoch [6/8], Step [20/810], Loss: 3.1415\n",
      "Epoch [6/8], Step [30/810], Loss: 4.0299\n",
      "Epoch [6/8], Step [40/810], Loss: 2.5914\n",
      "Epoch [6/8], Step [50/810], Loss: 2.5918\n",
      "Epoch [6/8], Step [60/810], Loss: 3.4946\n",
      "Epoch [6/8], Step [70/810], Loss: 2.8123\n",
      "Epoch [6/8], Step [80/810], Loss: 4.2928\n",
      "Epoch [6/8], Step [90/810], Loss: 4.5845\n",
      "Epoch [6/8], Step [100/810], Loss: 3.5952\n",
      "Epoch [6/8], Step [110/810], Loss: 3.2632\n",
      "Epoch [6/8], Step [120/810], Loss: 2.4481\n",
      "Epoch [6/8], Step [130/810], Loss: 3.0811\n",
      "Epoch [6/8], Step [140/810], Loss: 4.4359\n",
      "Epoch [6/8], Step [150/810], Loss: 3.6024\n",
      "Epoch [6/8], Step [160/810], Loss: 3.1049\n",
      "Epoch [6/8], Step [170/810], Loss: 2.8310\n",
      "Epoch [6/8], Step [180/810], Loss: 3.7148\n",
      "Epoch [6/8], Step [190/810], Loss: 3.1721\n",
      "Epoch [6/8], Step [200/810], Loss: 3.1018\n",
      "Epoch [6/8], Step [210/810], Loss: 2.7025\n",
      "Epoch [6/8], Step [220/810], Loss: 2.9294\n",
      "Epoch [6/8], Step [230/810], Loss: 2.4902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/8], Step [240/810], Loss: 3.3974\n",
      "Epoch [6/8], Step [250/810], Loss: 2.7997\n",
      "Epoch [6/8], Step [260/810], Loss: 1.9445\n",
      "Epoch [6/8], Step [270/810], Loss: 3.0264\n",
      "Epoch [6/8], Step [280/810], Loss: 2.5551\n",
      "Epoch [6/8], Step [290/810], Loss: 3.3555\n",
      "Epoch [6/8], Step [300/810], Loss: 3.3480\n",
      "Epoch [6/8], Step [310/810], Loss: 3.1951\n",
      "Epoch [6/8], Step [320/810], Loss: 2.8458\n",
      "Epoch [6/8], Step [330/810], Loss: 3.6322\n",
      "Epoch [6/8], Step [340/810], Loss: 2.4903\n",
      "Epoch [6/8], Step [350/810], Loss: 3.2708\n",
      "Epoch [6/8], Step [360/810], Loss: 2.7056\n",
      "Epoch [6/8], Step [370/810], Loss: 4.4311\n",
      "Epoch [6/8], Step [380/810], Loss: 3.1007\n",
      "Epoch [6/8], Step [390/810], Loss: 1.9987\n",
      "Epoch [6/8], Step [400/810], Loss: 3.3862\n",
      "Epoch [6/8], Step [410/810], Loss: 3.0097\n",
      "Epoch [6/8], Step [420/810], Loss: 2.8608\n",
      "Epoch [6/8], Step [430/810], Loss: 2.4789\n",
      "Epoch [6/8], Step [440/810], Loss: 2.4673\n",
      "Epoch [6/8], Step [450/810], Loss: 3.7502\n",
      "Epoch [6/8], Step [460/810], Loss: 3.6793\n",
      "Epoch [6/8], Step [470/810], Loss: 3.1146\n",
      "Epoch [6/8], Step [480/810], Loss: 2.8095\n",
      "Epoch [6/8], Step [490/810], Loss: 2.4187\n",
      "Epoch [6/8], Step [500/810], Loss: 3.1943\n",
      "Epoch [6/8], Step [510/810], Loss: 2.3212\n",
      "Epoch [6/8], Step [520/810], Loss: 3.0512\n",
      "Epoch [6/8], Step [530/810], Loss: 3.1530\n",
      "Epoch [6/8], Step [540/810], Loss: 4.6972\n",
      "Epoch [6/8], Step [550/810], Loss: 3.8241\n",
      "Epoch [6/8], Step [560/810], Loss: 3.3682\n",
      "Epoch [6/8], Step [570/810], Loss: 4.6382\n",
      "Epoch [6/8], Step [580/810], Loss: 3.9281\n",
      "Epoch [6/8], Step [590/810], Loss: 3.1195\n",
      "Epoch [6/8], Step [600/810], Loss: 2.2190\n",
      "Epoch [6/8], Step [610/810], Loss: 3.6504\n",
      "Epoch [6/8], Step [620/810], Loss: 2.6096\n",
      "Epoch [6/8], Step [630/810], Loss: 3.8253\n",
      "Epoch [6/8], Step [640/810], Loss: 2.7841\n",
      "Epoch [6/8], Step [650/810], Loss: 2.8683\n",
      "Epoch [6/8], Step [660/810], Loss: 2.5207\n",
      "Epoch [6/8], Step [670/810], Loss: 3.3802\n",
      "Epoch [6/8], Step [680/810], Loss: 2.8194\n",
      "Epoch [6/8], Step [690/810], Loss: 3.6477\n",
      "Epoch [6/8], Step [700/810], Loss: 4.0214\n",
      "Epoch [6/8], Step [710/810], Loss: 2.8755\n",
      "Epoch [6/8], Step [720/810], Loss: 2.7322\n",
      "Epoch [6/8], Step [730/810], Loss: 4.3207\n",
      "Epoch [6/8], Step [740/810], Loss: 3.5524\n",
      "Epoch [6/8], Step [750/810], Loss: 2.6782\n",
      "Epoch [6/8], Step [760/810], Loss: 3.1993\n",
      "Epoch [6/8], Step [770/810], Loss: 3.3311\n",
      "Epoch [6/8], Step [780/810], Loss: 3.6829\n",
      "Epoch [6/8], Step [790/810], Loss: 3.7838\n",
      "Epoch [6/8], Step [800/810], Loss: 3.4655\n",
      "[['heart size within normal limits stable mediastinal and hilar contours.', 'no alveolar consolidation no findings of pleural effusion or pulmonary edema.', 'chronic appearing contour deformity of the right <unk> th rib again noted suggestive of old injury.']]\n",
      "['the size and normal limits mediastinal and hilar contours.', 'the pleural consolidation no findings of pleural effusion pulmonary edema.', 'the appearing left irregularity of the right <unk> th rib again noted stable of old injury.', '.', '.', '.', '.']\n",
      "Bleu_1: 0.649\n",
      "Bleu_2: 0.517\n",
      "Bleu_3: 0.418\n",
      "Bleu_4: 0.342\n",
      "ROUGE_L: 0.627\n",
      "CIDEr: 2.689\n",
      "Epoch [7/8], Step [0/810], Loss: 3.4981\n",
      "Epoch [7/8], Step [10/810], Loss: 2.6745\n",
      "Epoch [7/8], Step [20/810], Loss: 3.2947\n",
      "Epoch [7/8], Step [30/810], Loss: 2.4526\n",
      "Epoch [7/8], Step [40/810], Loss: 2.5450\n",
      "Epoch [7/8], Step [50/810], Loss: 2.4245\n",
      "Epoch [7/8], Step [60/810], Loss: 3.1624\n",
      "Epoch [7/8], Step [70/810], Loss: 3.1881\n",
      "Epoch [7/8], Step [80/810], Loss: 3.7108\n",
      "Epoch [7/8], Step [90/810], Loss: 3.4267\n",
      "Epoch [7/8], Step [100/810], Loss: 2.9317\n",
      "Epoch [7/8], Step [110/810], Loss: 2.0204\n",
      "Epoch [7/8], Step [120/810], Loss: 3.5463\n",
      "Epoch [7/8], Step [130/810], Loss: 2.4839\n",
      "Epoch [7/8], Step [140/810], Loss: 2.3798\n",
      "Epoch [7/8], Step [150/810], Loss: 1.6308\n",
      "Epoch [7/8], Step [160/810], Loss: 3.2802\n",
      "Epoch [7/8], Step [170/810], Loss: 4.1595\n",
      "Epoch [7/8], Step [180/810], Loss: 3.4316\n",
      "Epoch [7/8], Step [190/810], Loss: 2.4529\n",
      "Epoch [7/8], Step [200/810], Loss: 3.1648\n",
      "Epoch [7/8], Step [210/810], Loss: 2.6874\n",
      "Epoch [7/8], Step [220/810], Loss: 2.8228\n",
      "Epoch [7/8], Step [230/810], Loss: 3.0304\n",
      "Epoch [7/8], Step [240/810], Loss: 3.7262\n",
      "Epoch [7/8], Step [250/810], Loss: 2.1066\n",
      "Epoch [7/8], Step [260/810], Loss: 4.4442\n",
      "Epoch [7/8], Step [270/810], Loss: 2.6794\n",
      "Epoch [7/8], Step [280/810], Loss: 2.5120\n",
      "Epoch [7/8], Step [290/810], Loss: 3.7303\n",
      "Epoch [7/8], Step [300/810], Loss: 3.5806\n",
      "Epoch [7/8], Step [310/810], Loss: 4.6931\n",
      "Epoch [7/8], Step [320/810], Loss: 3.7795\n",
      "Epoch [7/8], Step [330/810], Loss: 3.6190\n",
      "Epoch [7/8], Step [340/810], Loss: 4.2037\n",
      "Epoch [7/8], Step [350/810], Loss: 2.5934\n",
      "Epoch [7/8], Step [360/810], Loss: 4.0958\n",
      "Epoch [7/8], Step [370/810], Loss: 4.4065\n",
      "Epoch [7/8], Step [380/810], Loss: 3.3846\n",
      "Epoch [7/8], Step [390/810], Loss: 3.4180\n",
      "Epoch [7/8], Step [400/810], Loss: 3.4072\n",
      "Epoch [7/8], Step [410/810], Loss: 3.7012\n",
      "Epoch [7/8], Step [420/810], Loss: 2.9582\n",
      "Epoch [7/8], Step [430/810], Loss: 4.0643\n",
      "Epoch [7/8], Step [440/810], Loss: 2.3538\n",
      "Epoch [7/8], Step [450/810], Loss: 2.5275\n",
      "Epoch [7/8], Step [460/810], Loss: 2.7392\n",
      "Epoch [7/8], Step [470/810], Loss: 3.6510\n",
      "Epoch [7/8], Step [480/810], Loss: 2.2399\n",
      "Epoch [7/8], Step [490/810], Loss: 2.4670\n",
      "Epoch [7/8], Step [500/810], Loss: 3.3268\n",
      "Epoch [7/8], Step [510/810], Loss: 2.4851\n",
      "Epoch [7/8], Step [520/810], Loss: 2.9530\n",
      "Epoch [7/8], Step [530/810], Loss: 2.1455\n",
      "Epoch [7/8], Step [540/810], Loss: 2.7216\n",
      "Epoch [7/8], Step [550/810], Loss: 3.2770\n",
      "Epoch [7/8], Step [560/810], Loss: 3.4836\n",
      "Epoch [7/8], Step [570/810], Loss: 3.2799\n",
      "Epoch [7/8], Step [580/810], Loss: 2.5794\n",
      "Epoch [7/8], Step [590/810], Loss: 3.6602\n",
      "Epoch [7/8], Step [600/810], Loss: 4.5765\n",
      "Epoch [7/8], Step [610/810], Loss: 3.5027\n",
      "Epoch [7/8], Step [620/810], Loss: 2.3473\n",
      "Epoch [7/8], Step [630/810], Loss: 2.8500\n",
      "Epoch [7/8], Step [640/810], Loss: 2.8775\n",
      "Epoch [7/8], Step [650/810], Loss: 2.8803\n",
      "Epoch [7/8], Step [660/810], Loss: 4.1015\n",
      "Epoch [7/8], Step [670/810], Loss: 2.9000\n",
      "Epoch [7/8], Step [680/810], Loss: 3.6535\n",
      "Epoch [7/8], Step [690/810], Loss: 2.9673\n",
      "Epoch [7/8], Step [700/810], Loss: 4.6450\n",
      "Epoch [7/8], Step [710/810], Loss: 3.1721\n",
      "Epoch [7/8], Step [720/810], Loss: 3.4921\n",
      "Epoch [7/8], Step [730/810], Loss: 3.2217\n",
      "Epoch [7/8], Step [740/810], Loss: 2.9002\n",
      "Epoch [7/8], Step [750/810], Loss: 3.6432\n",
      "Epoch [7/8], Step [760/810], Loss: 2.8556\n",
      "Epoch [7/8], Step [770/810], Loss: 2.9363\n",
      "Epoch [7/8], Step [780/810], Loss: 2.3997\n",
      "Epoch [7/8], Step [790/810], Loss: 3.7674\n",
      "Epoch [7/8], Step [800/810], Loss: 2.5502\n",
      "[['cardiomediastinal silhouettes are within normal limits.', 'lungs are clear without focal consolidation pneumothorax or pleural effusion.', 'vague nodular density right upper lobe overlying the right anterior <unk> and posterior th ribs.', 'this could represent healing fracture or superimposed structures.', 'bony thorax is unremarkable.']]\n",
      "['the silhouette are within normal limits.', 'the are clear focal consolidation or pleural effusion.', 'the opacity opacity in mid lobe opacity the anterior anterior th posterior th rib.', 'the study indicate healing fracture or superimposed <unk>.', 'the structures and unremarkable.', '.', '.']\n",
      "Bleu_1: 0.590\n",
      "Bleu_2: 0.469\n",
      "Bleu_3: 0.380\n",
      "Bleu_4: 0.313\n",
      "ROUGE_L: 0.577\n",
      "CIDEr: 2.325\n"
     ]
    }
   ],
   "source": [
    "args, val_loader, encoderCNN, sentLSTM, wordLSTM, vocab = script(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###       -      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderCNN(\n",
       "  (cnn): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): ReLU(inplace=True)\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU(inplace=True)\n",
       "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): ReLU(inplace=True)\n",
       "      (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (17): ReLU(inplace=True)\n",
       "      (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (20): ReLU(inplace=True)\n",
       "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (22): ReLU(inplace=True)\n",
       "      (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (24): ReLU(inplace=True)\n",
       "      (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (26): ReLU(inplace=True)\n",
       "      (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (29): ReLU(inplace=True)\n",
       "      (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (31): ReLU(inplace=True)\n",
       "      (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (33): ReLU(inplace=True)\n",
       "      (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (35): ReLU(inplace=True)\n",
       "      (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (dense_m): DenseNet(\n",
       "    (features): Sequential(\n",
       "      (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu0): ReLU(inplace=True)\n",
       "      (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (denseblock1): _DenseBlock(\n",
       "        (denselayer1): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer2): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer3): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer4): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer5): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer6): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (transition1): _Transition(\n",
       "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "      (denseblock2): _DenseBlock(\n",
       "        (denselayer1): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer2): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer3): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer4): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer5): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer6): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer7): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer8): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer9): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer10): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer11): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer12): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (transition2): _Transition(\n",
       "        (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "      (denseblock3): _DenseBlock(\n",
       "        (denselayer1): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer2): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer3): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer4): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer5): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer6): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer7): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer8): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer9): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer10): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer11): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer12): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer13): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer14): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer15): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer16): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer17): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer18): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer19): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer20): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer21): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer22): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer23): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer24): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (transition3): _Transition(\n",
       "        (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "      (denseblock4): _DenseBlock(\n",
       "        (denselayer1): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer2): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer3): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer4): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer5): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer6): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer7): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer8): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer9): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer10): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer11): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer12): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer13): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer14): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer15): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer16): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=1024, out_features=8, bias=True)\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoderCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoderCNN.eval()\n",
    "sentLSTM.eval()\n",
    "wordLSTM.eval()\n",
    "\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (images, captions, prob) in enumerate(val_loader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 3, 224, 224])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 6, 17])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  1,  38, 110,   9, 109,   2,   0,   0,   0,   0],\n",
       "         [  1,  15, 201,   2,   0,   0,   0,   0,   0,   0],\n",
       "         [  1,  53,   6, 120,   9,  11,   2,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
       "\n",
       "        [[  1,  23,  13,   6,  18, 155, 196,  15,  20,  57],\n",
       "         [  1,  53,  30,   6,   7, 103,  10,  11,  12,   2],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
       "\n",
       "        [[  1,  11,  53,   2,   0,   0,   0,   0,   0,   0],\n",
       "         [  1,  14,  13,   2,   0,   0,   0,   0,   0,   0],\n",
       "         [  1,  87,  44,  45,  37, 188,   2,   0,   0,   0],\n",
       "         [  1,  15,  16,   2,   0,   0,   0,   0,   0,   0],\n",
       "         [  1,  15,  18,  19,   2,   0,   0,   0,   0,   0],\n",
       "         [  1, 112, 111,   2,   0,   0,   0,   0,   0,   0]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions[:3, :, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.to(args.device)\n",
    "captions = captions.to(args.device)\n",
    "prob = prob.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_enc_out = encoderCNN(images)\n",
    "\n",
    "topics, ps = sentLSTM(vis_enc_out, torch.ones_like(captions), args.device)\n",
    "\n",
    "# loss_sent = criterion_stop_val(ps.view(-1, 2), prob.view(-1))\n",
    "\n",
    "# loss_word = torch.tensor([0.0]).to(args.device)\n",
    "\n",
    "pred_words = torch.zeros((captions.shape[0], captions.shape[1], captions.shape[2])).to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000, 22.0881, 17.5690, 10.0925,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.6939,  0.9649,  0.0000, 18.9178,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000, 51.1835, 18.9786,  0.0000, 19.4284,  0.0000,  5.0696,  0.9998,\n",
       "          0.0000,  0.0000,  0.7694,  0.0000,  0.1152,  1.4709,  0.6992, 13.1206,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000]], device='cuda:0',\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics[:2, 0, :20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1, 38],\n",
       "        [ 1, 23],\n",
       "        [ 1, 11],\n",
       "        [ 1, 53],\n",
       "        [ 1, 23],\n",
       "        [ 1, 23],\n",
       "        [ 1, 23],\n",
       "        [ 1, 11]], device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions[:, 0, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 6, 17])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_words[:, :, 0] = 1\n",
    "pred_words = pred_words.long()\n",
    "pred_words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(captions.shape[1]):\n",
    "    for j in range(2, captions.shape[2]):\n",
    "        pred_words[:, i, :j] = wordLSTM(topics[:, i, :], pred_words[:, i, :j]).argmax(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1, 23, 53, 25, 11, 29, 30,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1, 23, 53, 25, 11, 29, 30,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1, 23, 53, 25, 11, 29, 30,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1, 23, 53, 25, 11, 29, 30,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1, 23, 53, 25, 11, 29, 30,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1, 23, 53, 25, 11, 29, 30,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1, 23, 53, 25, 11, 29, 30,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1, 23, 53, 25, 11, 29, 30,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_words[:, 0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start>\n",
      "the\n",
      "heart\n",
      "size\n",
      "and\n",
      "pulmonary\n",
      "vascularity\n",
      "appear\n",
      "within\n",
      "normal\n",
      "limits\n",
      "<end>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n"
     ]
    }
   ],
   "source": [
    "for i in pred_words[0, 0, :]:\n",
    "    print(vocab.idx2word[int(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start>\n",
      "the\n",
      "lungs\n",
      "are\n",
      "free\n",
      "of\n",
      "focal\n",
      "airspace\n",
      "disease\n",
      "<end>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n"
     ]
    }
   ],
   "source": [
    "for i in pred_words[0, 1, :]:\n",
    "    print(vocab.idx2word[int(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
